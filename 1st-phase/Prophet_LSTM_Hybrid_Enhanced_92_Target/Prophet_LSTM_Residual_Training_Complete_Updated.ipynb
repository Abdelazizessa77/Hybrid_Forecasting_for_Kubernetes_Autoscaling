{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b7ba7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a6f427",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edad1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_excel(\"usask.sec.min_short_v2.xlsx\")\n",
    "df.columns = ['minute', 'requests']\n",
    "df['minute'] = pd.to_datetime(df['minute'], unit='m', origin='unix')\n",
    "df.rename(columns={'minute': 'ds', 'requests': 'y'}, inplace=True)\n",
    "df['ds'] = pd.to_datetime(df['ds'])\n",
    "df = df.sort_values('ds')\n",
    "df.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5fdd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet import Prophet\n",
    "\n",
    "# Use Prophet to generate real forecasts\n",
    "prophet_df = df[['ds', 'y']].copy()\n",
    "model = Prophet(daily_seasonality=True)\n",
    "model.fit(prophet_df)\n",
    "\n",
    "# Forecast next values (in-sample)\n",
    "forecast = model.predict(prophet_df)\n",
    "df['yhat'] = forecast['yhat']\n",
    "df['residual'] = df['y'] - df['yhat']\n",
    "merged = df[['ds', 'residual']].dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd897fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaled = scaler.fit_transform(merged[['residual']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8486dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, window_size=30):\n",
    "    X, y = [], []\n",
    "    for i in range(window_size, len(data)):\n",
    "        X.append(data[i-window_size:i])\n",
    "        y.append(data[i])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "window_size = 30\n",
    "X, y = create_sequences(scaled, window_size)\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4428043b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "MODEL_DIR = \"hybrid_lstm_models\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "# Define LSTM model\n",
    "model_lstm = Sequential([\n",
    "    Input(shape=(X.shape[1], X.shape[2])),\n",
    "    LSTM(64, activation='tanh'),\n",
    "    Dense(1)\n",
    "])\n",
    "model_lstm.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Callbacks\n",
    "checkpoint_path = os.path.join(MODEL_DIR, \"best_lstm_model.keras\")\n",
    "es = EarlyStopping(monitor='val_loss', patience=5, min_delta=1e-5, restore_best_weights=True)\n",
    "mc = ModelCheckpoint(checkpoint_path, monitor='val_loss', save_best_only=True)\n",
    "\n",
    "# Train model\n",
    "history = model_lstm.fit(\n",
    "    X, y,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[es, mc],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fa3117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training loss and MAE\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title(\"Loss (MSE)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['mae'], label='Training MAE')\n",
    "plt.plot(history.history['val_mae'], label='Validation MAE')\n",
    "plt.title(\"Mean Absolute Error (MAE)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MAE\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "metrics_plot_path = os.path.join(MODEL_DIR, \"training_metrics.png\")\n",
    "plt.savefig(metrics_plot_path, dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90690f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict residuals using trained model\n",
    "y_pred_scaled = model_lstm.predict(X)\n",
    "\n",
    "# Inverse transform\n",
    "y_true_rescaled = scaler.inverse_transform(y)\n",
    "y_pred_rescaled = scaler.inverse_transform(y_pred_scaled)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "mae = mean_absolute_error(y_true_rescaled, y_pred_rescaled)\n",
    "rmse = np.sqrt(mean_squared_error(y_true_rescaled, y_pred_rescaled))\n",
    "r2 = r2_score(y_true_rescaled, y_pred_rescaled)\n",
    "mape = np.mean(np.abs((y_true_rescaled - y_pred_rescaled) / y_true_rescaled)) * 100\n",
    "accuracy = 100 - mape\n",
    "\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"RÂ²: {r2:.4f}\")\n",
    "print(f\"MAPE: {mape:.2f}%\")\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
